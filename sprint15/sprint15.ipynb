{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題1】公式Exampleを分担して実行\n",
    "TensorFLowの公式Exampleを分担して実行してください。\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Neural Machine Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・翻訳では\"sequence to sequence\"という入力データを出力データへ変換する処理が行われる。（文全体から予測を行う）  \n",
    "・seq2seqは２つのRNN (Enconder & Decoder)から構成される（RNNを使うのはワードの前後関係から予測を行うため）  \n",
    "・Encoderで入力データをベクトルへ変換 => ベクトルをDecoderへ私し出力データを作成  \n",
    "・以下の例ではattentionというロジックを追加し翻訳の精度を高めている。(encoderで算出された重み？によってdecoder側で関連の強いワードにattentionがかかる様にする)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://download.tensorflow.org/data/spa-eng.zip', \n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    \n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "文字をベクトルへ置き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "class LanguageIndex():\n",
    "  def __init__(self, lang):\n",
    "    self.lang = lang\n",
    "    self.word2idx = {}\n",
    "    self.idx2word = {}\n",
    "    self.vocab = set()\n",
    "    \n",
    "    self.create_index()\n",
    "    \n",
    "  def create_index(self):\n",
    "    for phrase in self.lang:\n",
    "      self.vocab.update(phrase.split(' '))\n",
    "    \n",
    "    self.vocab = sorted(self.vocab)\n",
    "    \n",
    "    self.word2idx['<pad>'] = 0\n",
    "    for index, word in enumerate(self.vocab):\n",
    "      self.word2idx[word] = index + 1\n",
    "    \n",
    "    for word, index in self.word2idx.items():\n",
    "      self.idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "def load_dataset(path, num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    pairs = create_dataset(path, num_examples)\n",
    "\n",
    "    # index language using the class defined above    \n",
    "    inp_lang = LanguageIndex(sp for en, sp in pairs)\n",
    "    targ_lang = LanguageIndex(en for en, sp in pairs)\n",
    "    \n",
    "    # Vectorize the input and target languages\n",
    "    \n",
    "    # Spanish sentences\n",
    "    input_tensor = [[inp_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
    "    \n",
    "    # English sentences\n",
    "    target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
    "    \n",
    "    # Calculate max_length of input and output tensor\n",
    "    # Here, we'll set those to the longest sentence in the dataset\n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "    \n",
    "    # Padding the input and output tensor to the maximum length\n",
    "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
    "                                                                 maxlen=max_length_inp,\n",
    "                                                                 padding='post')\n",
    "    \n",
    "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
    "                                                                  maxlen=max_length_tar, \n",
    "                                                                  padding='post')\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(path_to_file, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000, 6000, 6000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "  if tf.test.is_gpu_available():\n",
    "    return tf.keras.layers.CuDNNGRU(units, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "  else:\n",
    "    return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = 1 - np.equal(real, 0)\n",
    "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.4758\n",
      "Epoch 1 Batch 100 Loss 1.3615\n",
      "Epoch 1 Batch 200 Loss 1.3432\n",
      "Epoch 1 Batch 300 Loss 1.2505\n",
      "Epoch 1 Loss 1.3335\n",
      "Time taken for 1 epoch 1585.4686510562897 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.0041\n",
      "Epoch 2 Batch 100 Loss 1.0037\n",
      "Epoch 2 Batch 200 Loss 0.8377\n",
      "Epoch 2 Batch 300 Loss 0.8596\n",
      "Epoch 2 Loss 0.9260\n",
      "Time taken for 1 epoch 1614.685038805008 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(inp, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.idx2word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x13e6facf8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAJwCAYAAAA5n02CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUf6J474AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b12a0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'esta es mi vida.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> quiero ir a pescar . <end>\n",
      "Predicted translation: i want to go fishing . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAJwCAYAAAC9GaqsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1H28aFtGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ee53f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I want to go fishing\n",
    "translate(u'quiero ir a pescar.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> que hermoso dia hoy ! . <end>\n",
      "Predicted translation: what s hot day ! <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAI+CAYAAAAvlndLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBB4AwGD+P/En7dWYml0tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13cb0d0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What a beautiful day today!\n",
    "translate(u'¡Qué hermoso día hoy!.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> creo que eso es lo que escribio ese chico . <end>\n",
      "Predicted translation: i think that s weird . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAHFCAYAAABhK4QMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b31f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### I think that that that that that boy wrote is wrong.\n",
    "translate(u'Creo que eso es lo que escribió ese chico.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題2】Iris（2値分類）をKerasで学習\n",
    "Sprint14で作成したIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"iris/iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "data = X_train\n",
    "labels = y_train\n",
    "input_data_shape = data.shape \n",
    "\n",
    "#Configure layer w/ keras\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(100, input_dim=4, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題3】Iris（多値分類）をKerasで学習\n",
    "Sprint14で作成したIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"iris/iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "#y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:,np.newaxis])\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "data = X_train\n",
    "labels = y_train\n",
    "\n",
    "\n",
    "#Configure layer w/ keras\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(100, input_dim=4, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題4】House PricesをKerasで学習\n",
    "Sprint14で作成したHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ori = pd.read_csv(\"/Users/naoki/Desktop/DIC/kaggle/housing_price/train.csv\")\n",
    "max_num_of_row = len(data_ori)\n",
    "data_loss_rate = data_ori.isnull().sum() / max_num_of_row * 100\n",
    "data_drop_5nan_col = data_ori.dropna(axis=1, thresh=max_num_of_row-5)\n",
    "data_to_use = data_drop_5nan_col.dropna(axis=0)\n",
    "data_to_use = data_to_use.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_featuer = ['OverallQual',\n",
    "       'GrLivArea',\n",
    "       'GarageCars',\n",
    "       'GarageArea',\n",
    "       'TotalBsmtSF',\n",
    "       '1stFlrSF',\n",
    "       'FullBath',\n",
    "       'TotRmsAbvGrd',\n",
    "       'YearBuilt',\n",
    "       'YearRemodAdd',\n",
    "      ]\n",
    "\n",
    "col_target = ['SalePrice']\n",
    "\n",
    "col = col_featuer + col_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_to_use[col]\n",
    "X = data[col_featuer].values\n",
    "Y = data[col_target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "data = x_train\n",
    "labels = y_train\n",
    "dim = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Configure layer w/ keras\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(100, input_dim=dim, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "model.fit(data, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題5】MNISTをKerasで学習\n",
    "Sprint14で作成したMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "x_train = x_train.astype(np.float)\n",
    "x_test = x_test.astype(np.float)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train_one_hot, test_size=0.2, random_state=0)\n",
    "data = X_train\n",
    "labels = y_train\n",
    "\n",
    "dim = data.shape[1]\n",
    "\n",
    "#Configure layer w/ keras\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(100, input_dim=dim, activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題6】（アドバンス課題）PyTorchへの書き換え\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iris 2値分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"iris/iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "#y = enc.fit_transform(y[:,np.newaxis])\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_classes = 1\n",
    "n_input = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden1)\n",
    "        self.fc2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.fc3 = nn.Linear(n_hidden2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.149..  Val Loss: 0.717.. \n",
      "Epoch: 2 Loss: 0.142..  Val Loss: 0.700.. \n",
      "Epoch: 3 Loss: 0.140..  Val Loss: 0.694.. \n",
      "Epoch: 4 Loss: 0.139..  Val Loss: 0.691.. \n",
      "Epoch: 5 Loss: 0.138..  Val Loss: 0.689.. \n",
      "Epoch: 6 Loss: 0.138..  Val Loss: 0.688.. \n",
      "Epoch: 7 Loss: 0.138..  Val Loss: 0.687.. \n",
      "Epoch: 8 Loss: 0.137..  Val Loss: 0.685.. \n",
      "Epoch: 9 Loss: 0.137..  Val Loss: 0.684.. \n",
      "Epoch: 10 Loss: 0.137..  Val Loss: 0.683.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "        \n",
    "        x_t = torch.from_numpy(mini_batch_x).float()\n",
    "        y_t = torch.from_numpy(mini_batch_y).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_t)\n",
    "        \n",
    "        loss = criterion(output, y_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_val_t = torch.from_numpy(X_val).float()\n",
    "            y_val_t = torch.from_numpy(y_val).float()\n",
    "            model.eval()\n",
    "            predictions = model(x_val_t)\n",
    "            test_loss += criterion(predictions, y_val_t)\n",
    "                \n",
    "        train_losses.append(train_loss/batch_size)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(\"Epoch: {}\".format(e+1),\n",
    "              \"Loss: {:.3f}.. \".format(train_loss/batch_size),\n",
    "              \"Val Loss: {:.3f}.. \".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iris 多クラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"iris/iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "#y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:,np.newaxis])\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_classes = 3\n",
    "n_input = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden1)\n",
    "        self.fc2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.fc3 = nn.Linear(n_hidden2, n_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.325..  Val Loss: 1.069.. \n",
      "Epoch: 2 Loss: 0.324..  Val Loss: 1.063.. \n",
      "Epoch: 3 Loss: 0.322..  Val Loss: 1.056.. \n",
      "Epoch: 4 Loss: 0.321..  Val Loss: 1.051.. \n",
      "Epoch: 5 Loss: 0.319..  Val Loss: 1.045.. \n",
      "Epoch: 6 Loss: 0.318..  Val Loss: 1.040.. \n",
      "Epoch: 7 Loss: 0.317..  Val Loss: 1.034.. \n",
      "Epoch: 8 Loss: 0.315..  Val Loss: 1.029.. \n",
      "Epoch: 9 Loss: 0.314..  Val Loss: 1.024.. \n",
      "Epoch: 10 Loss: 0.313..  Val Loss: 1.020.. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "        x_t = torch.from_numpy(mini_batch_x).float()\n",
    "        y_t = torch.from_numpy(mini_batch_y).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_t)\n",
    "        #pred = torch.max(output)\n",
    "        #print(pred_)\n",
    "        #loss = criterion(output, y_t)\n",
    "        loss = criterion(output, torch.max(y_t, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_val_t = torch.from_numpy(X_val).float()\n",
    "            y_val_t = torch.from_numpy(y_val).long()\n",
    "            model.eval()\n",
    "            predictions = model(x_val_t)\n",
    "            test_loss += criterion(predictions, torch.max(y_val_t, 1)[1])\n",
    "                \n",
    "        train_losses.append(train_loss/batch_size)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(\"Epoch: {}\".format(e+1),\n",
    "              \"Loss: {:.3f}.. \".format(train_loss/batch_size),\n",
    "              \"Val Loss: {:.3f}.. \".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Housing price 回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_ori = pd.read_csv(\"/Users/naoki/Desktop/DIC/kaggle/housing_price/train.csv\")\n",
    "max_num_of_row = len(data_ori)\n",
    "data_loss_rate = data_ori.isnull().sum() / max_num_of_row * 100\n",
    "data_drop_5nan_col = data_ori.dropna(axis=1, thresh=max_num_of_row-5)\n",
    "data_to_use = data_drop_5nan_col.dropna(axis=0)\n",
    "data_to_use = data_to_use.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_featuer = ['OverallQual',\n",
    "       'GrLivArea',\n",
    "       'GarageCars',\n",
    "       'GarageArea',\n",
    "       'TotalBsmtSF',\n",
    "       '1stFlrSF',\n",
    "       'FullBath',\n",
    "       'TotRmsAbvGrd',\n",
    "       'YearBuilt',\n",
    "       'YearRemodAdd',\n",
    "      ]\n",
    "\n",
    "col_target = ['SalePrice']\n",
    "\n",
    "col = col_featuer + col_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_to_use[col]\n",
    "X = data[col_featuer].values\n",
    "Y = data[col_target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X =scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "data = x_train\n",
    "labels = y_train\n",
    "dim = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 465152.230..  Val Loss: 9.478.. \n",
      "Epoch: 2 Loss: 465054.412..  Val Loss: 7.413.. \n",
      "Epoch: 3 Loss: 464643.179..  Val Loss: 6.067.. \n",
      "Epoch: 4 Loss: 463594.245..  Val Loss: 5.101.. \n",
      "Epoch: 5 Loss: 461559.468..  Val Loss: 4.359.. \n",
      "Epoch: 6 Loss: 458197.680..  Val Loss: 3.762.. \n",
      "Epoch: 7 Loss: 453184.630..  Val Loss: 3.264.. \n",
      "Epoch: 8 Loss: 446216.052..  Val Loss: 2.838.. \n",
      "Epoch: 9 Loss: 437009.099..  Val Loss: 2.468.. \n",
      "Epoch: 10 Loss: 425303.798..  Val Loss: 2.142.. \n"
     ]
    }
   ],
   "source": [
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "get_mini_batch_train = GetMiniBatch(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "        x_t = torch.from_numpy(mini_batch_x).float()\n",
    "        y_t = torch.from_numpy(mini_batch_y).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_t)\n",
    "        loss = torch.sqrt(criterion(output, y_t))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_val_t = torch.from_numpy(x_val).float()\n",
    "            y_val_t = torch.from_numpy(y_val).float()\n",
    "            model.eval()\n",
    "            predictions = model(x_val_t)\n",
    "            test_loss += torch.sqrt(criterion(torch.log(predictions), torch.log(y_val_t)))\n",
    "                \n",
    "        train_losses.append(train_loss/batch_size)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(\"Epoch: {}\".format(e+1),\n",
    "              \"Loss: {:.3f}.. \".format(train_loss/batch_size),\n",
    "              \"Val Loss: {:.3f}.. \".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "x_train = x_train.astype(np.float)\n",
    "x_test = x_test.astype(np.float)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "# trainとtestに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train_one_hot, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_classes = 10\n",
    "n_input = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden1)\n",
    "        self.fc2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.fc3 = nn.Linear(n_hidden2, n_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 276.012..  Val Loss: 2.296.. \n",
      "Epoch: 2 Loss: 272.123..  Val Loss: 2.160.. \n",
      "Epoch: 3 Loss: 245.122..  Val Loss: 1.990.. \n",
      "Epoch: 4 Loss: 234.765..  Val Loss: 1.920.. \n",
      "Epoch: 5 Loss: 227.666..  Val Loss: 1.866.. \n",
      "Epoch: 6 Loss: 222.191..  Val Loss: 1.836.. \n",
      "Epoch: 7 Loss: 219.314..  Val Loss: 1.818.. \n",
      "Epoch: 8 Loss: 217.569..  Val Loss: 1.808.. \n",
      "Epoch: 9 Loss: 216.515..  Val Loss: 1.801.. \n",
      "Epoch: 10 Loss: 215.773..  Val Loss: 1.796.. \n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "        x_t = torch.from_numpy(mini_batch_x).float()\n",
    "        y_t = torch.from_numpy(mini_batch_y).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_t)\n",
    "        #pred = torch.max(output)\n",
    "        #print(pred_)\n",
    "        #loss = criterion(output, y_t)\n",
    "        loss = criterion(output, torch.max(y_t, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_val_t = torch.from_numpy(X_val).float()\n",
    "            y_val_t = torch.from_numpy(y_val).long()\n",
    "            model.eval()\n",
    "            predictions = model(x_val_t)\n",
    "            test_loss += criterion(predictions, torch.max(y_val_t, 1)[1])\n",
    "                \n",
    "        train_losses.append(train_loss/batch_size)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(\"Epoch: {}\".format(e+1),\n",
    "              \"Loss: {:.3f}.. \".format(train_loss/batch_size),\n",
    "              \"Val Loss: {:.3f}.. \".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題7】（アドバンス課題）フレームワークの比較\n",
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。\n",
    "興味がある場合はTensorFlow、Keras、PyTorch以外にも触れてみましょう。\n",
    "視点例\n",
    "計算速度\n",
    "コードの行数・可読性\n",
    "用意されている機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorflow\n",
    "・\n",
    "\n",
    "##### Keras\n",
    "・Tensorflowをより使い易くするためのwrapper\n",
    "・可読性高い\n",
    "\n",
    "##### Pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
