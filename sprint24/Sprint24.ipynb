{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題1】各種手法の実行\n",
    "Keras公式のサンプルをスタートコードとします。これを元に、上記11個の項目全てを使用してください。\n",
    "例えばこの中でSimpleRNNとLSTMなどは並列関係であり、精度の比較が行えます。そういった関係を見つけて比較をしてください。\n",
    "なおConvLSTM2Dのみ2次元配列を受け付ける手法であり、他と単純な精度の比較はできません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "#RNNの入力と１つ前のシーケンスの出力に対し全結合を計算\n",
    "class MinimalRNNCell(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #input_shape[-1] : Features  self.units : Nodes\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        \n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import RNN\n",
    "\n",
    "def build_RNN(model, max_features, nodes):\n",
    "    cells = MinimalRNNCell(128)\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(RNN(cells, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "def build_SimpleRNN(model, max_features, nodes):\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "def build_GRU(model, max_features, nodes):\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "def build_LSTM(model, max_features, nodes):\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNNCell\n",
    "from keras.layers import RNN\n",
    "      \n",
    "def build_RNN_CELL(model, max_features, nodes):\n",
    "    cells = SimpleRNNCell(128)\n",
    "  \n",
    "    model.add(Embedding(max_features, nodes))\n",
    "    model.add(RNN(cells))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRUCell\n",
    "from keras.layers import RNN\n",
    "      \n",
    "def build_RNN_GRUCELL(model, max_features, nodes):\n",
    "    cells = GRUCell(128)\n",
    "  \n",
    "    model.add(Embedding(max_features, nodes))\n",
    "    model.add(RNN(cells))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTMCell\n",
    "from keras.layers import RNN\n",
    "      \n",
    "def build_RNN_LSTMCELL(model, max_features, nodes):\n",
    "    cells = LSTMCell(128)\n",
    "  \n",
    "    model.add(Embedding(max_features, nodes))\n",
    "    model.add(RNN(cells))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackedRNNCells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import StackedRNNCells\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTMCell\n",
    "      \n",
    "def build_RNN_StackedRNNCells(model, max_features, nodes):\n",
    "\n",
    "    cells = [\n",
    "    LSTMCell(128),\n",
    "    LSTMCell(128),\n",
    "    ]\n",
    "    \n",
    "    cells = StackedRNNCells(cells)\n",
    "  \n",
    "    model.add(Embedding(max_features, nodes))\n",
    "    model.add(RNN(cells))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import CuDNNGRU\n",
    "\n",
    "def build_CuDNNGRU(model, max_features, nodes):\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(CuDNNGRU(128)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import CuDNNLSTM\n",
    "\n",
    "def build_CuDNNLSTM(model, max_features, nodes):\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(CuDNNLSTM(128)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題2】比較結果の説明\n",
    "11の項目それぞれがどういうものなのかを説明してください。また、比較した結果を表やグラフで載せ、説明してください。今回は「RNNはそれほど詳しくないがタスクで必要になったためKerasのドキュメントを見た」という仮定を置きます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google colabrator上で各モデルを実行した。ConvRNN2Dを除いて入力データ、Epoch数、バッチ数、ノード数は全て同じ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 比較結果  \n",
    "・SimpleRNNに比べてより長期的な情報を考慮できるLSTM, GRUは、SimpleRNNより高い精度が出ている。  \n",
    "・計算速度はよりシンプルなモデルであるSimpleRNNの方が早い（GPUを使用していないモデルで比較した場合）  \n",
    "・GRUはLSTMを簡素化したモデルであるため、予想通り計算速度がLSTMに比べ早い  \n",
    "・GPUを使用したモデルは使用していないモデルに比べ計算速度が７倍ほど早い(GRU, LSTM共に)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RNN, StckedRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| RNN | 引数のCellsにRNNの処理を定義したインスタンスを渡すことで、任意のRNNモデルを構築する。 今回は、入力データの全結合と1ステップ前のデータの全結合を足しただけのモデルで実行した。 | Test accuracy: 0.7798 | 30s/epoch |\n",
    "| StackedRNN | 任意の複数のRNN layerインスタンスを引数で受け取り、内部で１つRNN layerとして処理を行う | Test accuracy: 0.76224 | 45s/epoch |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| SimpleRNN | 1step前の情報をある重みで全結合して入力情報と足し合わせることで時間的なデータの繋がりまたは文脈を考慮するモデルとなる | Test accuracy: 0.76224 | 45s/epoch |\n",
    "| SimpleRNNCell | インスタンスかしたSimpleRNNCellをkeras RNN layerに渡すことで、SimpleRNNと同等のRNNモデルを作ることができる | Test accuracy: 0.77884 | 40s/epoch |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| LSTM| SimpleRNNではかなり前の過去の情報を保存することができず、短い時間間隔でのデータの繋がりしか考慮することができなかった。 LSTMではデータを保存する機構を設け、長い時間間隔でのデータの繋がりを考慮することができるようになった。 | Test accuracy: 0.819 | 154s/epoch |\n",
    "| LSTMCell | インスタンスかしたLSTMCellをkeras RNN layerに渡すことで、LSTMRNNと同等のRNNモデルを作ることができる | Test accuracy: 0.81692 | 134s/epoch |\n",
    "| CuDNNLSTM | GPUを使用し高速化したLSTMモデルを提供 | Test accuracy: 0.81924  | 20s/epoch |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| GRU | LSTMをシンプルにしたモデル。入力ゲートと忘却ゲートを「更新ゲート」として１つのゲートに統合しています。 | Test accuracy: 0.81644 | 125s/epoch |\n",
    "| GRUCell | インスタンスかしたGRUCellをkeras RNN layerに渡すことで、GRURNNと同等のRNNモデルを作ることができる | Test accuracy: 0.81376 | 117s/epoch |\n",
    "| CuDNNGRU | GPUを使用し高速化したGRUモデルを提供 | Test accuracy: 0.81972 | 17s/epoch |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ConvRNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| GRU | 2次元（例：画像）+１次元(例：時間)の入力情報を2次元（例：画像)に対してConvを行い特徴量を抽出し、抽出された特徴量の時間方向の繋がりをRNNで考慮したモデル |  | 111s/epoch |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題3】（アドバンス課題）複数のデータセット間での比較\n",
    "単一のデータセットでの実験に留めず、他のデータセットでも実験してみます。\n",
    "データセット - Keras Documentation\n",
    "Kerasで簡単に利用できる自然言語データセットとしてロイターのニュースワイヤー トピックス分類があります。IMDBは2値分類であったが、こちらは46値分類の問題です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "def run_calculation2(func):\n",
    "\n",
    "      max_features = 20000\n",
    "      # cut texts after this number of words (among top max_features most common words)\n",
    "      maxlen = 80\n",
    "      batch_size = 32\n",
    "\n",
    "      print('Loading data...')\n",
    "      (x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "    \n",
    "      y_train = y_train[:,np.newaxis]\n",
    "      y_test = y_test[:,np.newaxis]\n",
    "      \n",
    "      enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "      y_train = enc.fit_transform(y_train)\n",
    "      y_test = enc.fit_transform(y_test)\n",
    "    \n",
    "      print(len(x_train), 'train sequences')\n",
    "      print(len(x_test), 'test sequences')\n",
    "\n",
    "      print('Pad sequences (samples x time)')\n",
    "      x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "      x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "      print('x_train shape:', x_train.shape)\n",
    "      print('x_test shape:', x_test.shape)\n",
    "\n",
    "      print('Build model...')\n",
    "      model = Sequential()\n",
    "      model = func(model, max_features, 128 )\n",
    "\n",
    "      print('Train...')\n",
    "      model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=6,\n",
    "                validation_data=(x_test, y_test))\n",
    "      score, acc = model.evaluate(x_test, y_test,\n",
    "                                  batch_size=batch_size)\n",
    "      print('Test score:', score)\n",
    "      print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "def build_SimpleRNN2(model, max_features, nodes, n_out):\n",
    "    model.add(Embedding(max_features, nodes))\n",
    "    model.add(SimpleRNN(nodes, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(n_out, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 比較結果  \n",
    "・IMABレビューの感情分析と同様の結果であった。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| SimpleRNN | 1step前の情報をある重みで全結合して入力情報と足し合わせることで時間的なデータの繋がりまたは文脈を考慮するモデルとなる | Test accuracy: 0.412733 | 20s/epoch |\n",
    "| SimpleRNNCell | インスタンスかしたSimpleRNNCellをkeras RNN layerに渡すことで、SimpleRNNと同等のRNNモデルを作ることができる |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| LSTM| SimpleRNNではかなり前の過去の情報を保存することができず、短い時間間隔でのデータの繋がりしか考慮することができなかった。 LSTMではデータを保存する機構を設け、長い時間間隔でのデータの繋がりを考慮することができるようになった。 | Test accuracy: 0.68165 | 55s/epoch |\n",
    "| CuDNNLSTM | GPUを使用し高速化したLSTMモデルを提供 | Test accuracy: 0.69145146  | 9s/epoch |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| モデル | 説明 | 精度 |速度 |\n",
    "|:-----------|:------------|:------------|:------------|\n",
    "| GRU | LSTMをシンプルにしたモデル。入力ゲートと忘却ゲートを「更新ゲート」として１つのゲートに統合しています。 | Test accuracy: 0.6838824 | 46s/epoch |\n",
    "| CuDNNGRU | GPUを使用し高速化したGRUモデルを提供 | Test accuracy: 0.680320 | 8s/epoch |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
