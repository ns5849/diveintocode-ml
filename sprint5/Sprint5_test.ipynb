{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ScratchClfEvaluation():\n",
    "\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _AND_logic(self, x, y):\n",
    "        tmp = x*0.5 + y*0.5 - 0.7\n",
    "        return (tmp >= 0).astype(int)\n",
    "\n",
    "\n",
    "    def _OR_logic(self, x, y):\n",
    "        tmp = x*0.5 + y*0.5 - 0.2\n",
    "        return (tmp >= 0).astype(int)\n",
    "\n",
    "\n",
    "    def _NAND_logic(self, x, y):\n",
    "        tmp = x*(-0.5) + y*(-0.5) + 0.7\n",
    "        return (tmp >= 0).astype(int)\n",
    "\n",
    "\n",
    "    def _XOR_logic(self, x, y):\n",
    "        tmp1 = self._NAND_logic(x, y)\n",
    "        tmp2 = self._OR_logic(x, y)\n",
    "        tmp = self._AND_logic(tmp1, tmp2)\n",
    "        return tmp\n",
    "\n",
    "    \n",
    "    def _cal_tp(self, test_target, result, pos_label=1):\n",
    "        if pos_label==1:\n",
    "            x = test_target\n",
    "            y = result     \n",
    "        elif pos_label==0:\n",
    "            x = self._NAND_logic(test_target, test_target)\n",
    "            y = self._NAND_logic(result, result)       \n",
    "\n",
    "        tmp = self._AND_logic(x, y)\n",
    "        return np.sum(tmp == 1)\n",
    "\n",
    "\n",
    "    def _cal_fp(self, test_target, result, pos_label=1):\n",
    "        if pos_label==1:\n",
    "            x = test_target\n",
    "            y = result     \n",
    "        elif pos_label==0:\n",
    "            x = self._NAND_logic(test_target, test_target)\n",
    "            y = self._NAND_logic(result, result)\n",
    "\n",
    "        tmp1 = self._XOR_logic(x, y)\n",
    "        tmp = self._AND_logic(tmp1, y)\n",
    "        return np.sum(tmp == 1)\n",
    "\n",
    "\n",
    "    def _cal_tn(self, test_target, result, pos_label=1):\n",
    "        if pos_label==0:\n",
    "            x = test_target\n",
    "            y = result     \n",
    "        elif pos_label==1:\n",
    "            x = self._NAND_logic(test_target, test_target)\n",
    "            y = self._NAND_logic(result, result)\n",
    "\n",
    "        tmp = self._AND_logic(x, y)\n",
    "        return np.sum(tmp == 1)\n",
    "\n",
    "\n",
    "    def _cal_fn(self, test_target, result, pos_label=1):\n",
    "        if pos_label==1:\n",
    "            x = test_target\n",
    "            y = result     \n",
    "        elif pos_label==0:\n",
    "            x = self._NAND_logic(test_target, test_target)\n",
    "            y = self._NAND_logic(result, result)\n",
    "\n",
    "        tmp1 = self._XOR_logic(x, y)\n",
    "        tmp2 = self._AND_logic(tmp1, x)\n",
    "        return np.sum(tmp2 == 1)\n",
    "\n",
    "\n",
    "    def eval_tpr(self, ans, pred, pos_label=1): \n",
    "        sum_of_pos = np.sum(ans == int(pos_label))\n",
    "        tpr = self._cal_tp(ans, pred, pos_label) / sum_of_pos\n",
    "        return tpr\n",
    "\n",
    "\n",
    "    def eval_fpr(self, ans, pred, pos_label=1):\n",
    "        sum_of_neg = np.sum(ans != int(pos_label))\n",
    "        fpr = self._cal_fp(ans, pred, pos_label) / sum_of_neg\n",
    "        return fpr\n",
    "    \n",
    "    \n",
    "    def eval_accuracy(self, ans, pred, pos_label=1):\n",
    "        numer = self._cal_tp(ans, pred) + self._cal_tn(ans, pred)\n",
    "        denom = self._cal_tp(ans, pred) + self._cal_tn(ans, pred) + self._cal_fp(ans, pred) + self._cal_fn(ans, pred)\n",
    "        print(\"tp={} tn={} fp={} fn={}\".format(self._cal_tp(ans, pred), \n",
    "                                               self._cal_tn(ans, pred),\n",
    "                                               self._cal_fp(ans, pred),\n",
    "                                               self._cal_fn(ans, pred)))\n",
    "        \n",
    "        return numer / denom\n",
    "    \n",
    "    \n",
    "    def eval_precision(self, ans, pred, pos_label=1):\n",
    "        numer = self._cal_tp(ans, pred)\n",
    "        denom = self._cal_tp(ans, pred) + self._cal_fp(ans, pred)\n",
    "        \n",
    "        return numer / denom\n",
    "\n",
    "    \n",
    "    def eval_recall(self, ans, pred, pos_label=1):\n",
    "        numer = self._cal_tp(ans, pred)\n",
    "        denom = self._cal_tp(ans, pred) + self._cal_fn(ans, pred)\n",
    "        \n",
    "        return numer / denom\n",
    "    \n",
    "    \n",
    "    def eval_f1(self, ans, pred, pos_label=1):\n",
    "        numer = 2 * self.eval_precision(ans, pred) * self.eval_recall(ans, pred)\n",
    "        denom = self.eval_precision(ans, pred) + self.eval_recall(ans, pred)\n",
    "        \n",
    "        return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_data_set = load_iris()\n",
    "x = pd.DataFrame(iris_data_set.data, columns=iris_data_set.feature_names)    #Put explanatory variable into x as pandasdata frame\n",
    "y = pd.DataFrame(iris_data_set.target, columns=['Species'])    #Put iris response variable into y as pandasdata frame\n",
    "df = pd.concat([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  petal length (cm)  Species\n",
       "50                7.0                4.7        1\n",
       "51                6.4                4.5        1\n",
       "52                6.9                4.9        1\n",
       "53                5.5                4.0        1\n",
       "54                6.5                4.6        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = df.columns.values\n",
    "data = df[[col_name[0], col_name[2], col_name[4]]]\n",
    "data = data[data[\"Species\"] != 0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class ScratchSVMClassifier(ScratchClfEvaluation):\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, verbose, C=0, threshold=1e-5, hit_vector_cnt_threshold=5, kernel='linear'):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.C = C\n",
    "        self.threshold = threshold\n",
    "        if hit_vector_cnt_threshold >= 2:\n",
    "            self.hit_vector_cnt_threshold = hit_vector_cnt_threshold\n",
    "        else:\n",
    "            self.hit_vector_cnt_threshold = 2\n",
    "        self.kernel = kernel\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意 \n",
    "        self.lam = 0\n",
    "        self.sp_vector = 0\n",
    "        self.num_of_feature = 0\n",
    "        self.num_of_samples = 0\n",
    "        self.label0_val = 0\n",
    "        self.label1_val = 0\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        # 1-1. データを shape(n_feature, n_samples)へ整形, θをshape(n_feature, 1)へ整形　h=dot( (θ)t, X)とするため。\n",
    "        train_feature = X.T\n",
    "        train_target = y.reshape(1, len(y))\n",
    "        test_feature = X_val.T\n",
    "        test_target = y_val.reshape(1, len(y_val))\n",
    "        self.num_of_feature = train_feature.shape[0]\n",
    "        self.num_of_samples = train_feature.shape[1]\n",
    "        \n",
    "        # 1-2. Yを-1 or 1に規格化\n",
    "        self.label0_val = max(y)\n",
    "        self.label1_val = min(y)\n",
    "        train_target[train_target == self.label0_val] = -1\n",
    "        train_target[train_target == self.label1_val] = 1        \n",
    "        test_target[test_target == self.label0_val] = -1\n",
    "        test_target[test_target == self.label1_val] = 1\n",
    "        \n",
    "        # 1-3. 準備 サポートベクターの検出のためのFeature+Target行列を用意\n",
    "        data_source = np.concatenate((train_feature, train_target), axis=0)\n",
    "        HIT_LABEL_CNT_THRESHOLD = (int)(self.hit_vector_cnt_threshold / 2)\n",
    "        \n",
    "        # 1-4. 準備 適当な値でλを定義(random)、サンプル数分準備\n",
    "        LAMBDA_INIT_MIN = 1\n",
    "        LAMBDA_INIT_MAX = 10\n",
    "        LAMBDA_INIT_SCALE = 1e-07\n",
    "        self.lam = np.random.randint(LAMBDA_INIT_MIN, LAMBDA_INIT_MAX, train_target.shape[1]) * LAMBDA_INIT_SCALE\n",
    "        self.lam = np.reshape(self.lam, (1, len(self.lam)))\n",
    "        self.lam_cal_log = np.zeros((1, (len(self.lam))))\n",
    "        print(\"Initial lambda:\\n{}\".format(self.lam))\n",
    "\n",
    "        # 2. 最急降下法(Loopをiter回だけ回す)　\n",
    "        for i in range(0, self.iter):\n",
    "            self.lam = self._gradient_descent(train_feature, train_target)\n",
    "            if self.hit_vector_cnt_threshold <= np.sum(self.lam > self.threshold):\n",
    "                #学習データからサポートベクターを抜き出す\n",
    "                #data_source = np.concatenate([data_source, self.lam], axis=0)\n",
    "                selecter = self.lam * np.ones((data_source.shape[0], 1))\n",
    "                sp_vector = data_source[selecter > self.threshold]\n",
    "                sp_vector = sp_vector.reshape(data_source.shape[0], (int)(len(sp_vector)/data_source.shape[0]))\n",
    "                #抜き出したサポートベクターが+/-の両方含んでいる場合ループを抜けて計算を終了。サポートベクターをメンバ変数に保存\n",
    "                label_p_cnt = np.sum([sp_vector[sp_vector.shape[0] - 1] == 1]) \n",
    "                label_n_cnt = np.sum([sp_vector[sp_vector.shape[0] - 1] == -1])\n",
    "                if label_p_cnt >= HIT_LABEL_CNT_THRESHOLD & label_n_cnt >= HIT_LABEL_CNT_THRESHOLD:\n",
    "                    print(\"Loop count={}\".format(i))\n",
    "                    print(\"Support vector=\\n{}\".format(sp_vector))\n",
    "                    print(\"Labe count 1:[{}] -1:[{}]\".format(label_p_cnt, label_n_cnt))\n",
    "                    self.sp_vector = sp_vector\n",
    "                    self.lam = self.lam[self.lam > self.threshold]\n",
    "                    print(\"accuracy:\",self.cal_accuracy(train_target, self._test_predict(train_feature)))\n",
    "                    break\n",
    "                    \n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        # 入力値を整形\n",
    "        X = X.T\n",
    "\n",
    "        x_sn = self.sp_vector[0:self.sp_vector.shape[0] - 1]\n",
    "        x_sn = x_sn.reshape((self.num_of_feature, x_sn.shape[1]))\n",
    "        y_sn = self.sp_vector[self.sp_vector.shape[0] - 1].reshape((1, x_sn.shape[1]))    \n",
    "        tmp1 = self._svm_kernel_function(X, x_sn)\n",
    "        #print(\"lam=\",self.lam.shape)\n",
    "        #print(\"y_sn=\",y_sn.shape)\n",
    "        #print(\"tmp1=\",tmp1.shape)\n",
    "        tmp2 = self.lam.T * y_sn * tmp1\n",
    "        result = np.sum(tmp2, axis=1)\n",
    "        result[result < 0] = -1\n",
    "        result[result >= 0] = 1\n",
    "        result = result.astype('int8').T\n",
    "        \n",
    "        return self._standval_to_actval(result)\n",
    "\n",
    "    #def cal_confusion_matrix(self, y_pred, y):\n",
    "        \n",
    "    def cal_accuracy(self, y_pred, y):\n",
    "        return self.eval_accuracy(self._actval_to_standval(y_pred), self._actval_to_standval(y))\n",
    "            \n",
    "    def cal_precision(self, y_pred, y):\n",
    "        return self.eval_precision(self._actval_to_standval(y_pred), self._actval_to_standval(y))\n",
    "        \n",
    "    def cal_recall(self, y_pred, y):\n",
    "        return self.eval_recall(self._actval_to_standval(y_pred), self._actval_to_standval(y))\n",
    "        \n",
    "    def cal_f1(self, y_pred, y):\n",
    "        return self.eval_f1(self._actval_to_standval(y_pred), self._actval_to_standval(y))\n",
    "    \n",
    "    def _test_predict(self, X):\n",
    "        \"\"\"\n",
    "        SVMを使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        \n",
    "        x_sn = self.sp_vector[0:self.sp_vector.shape[0] - 1]\n",
    "        x_sn = x_sn.reshape((self.num_of_feature, x_sn.shape[1]))\n",
    "        y_sn = self.sp_vector[self.sp_vector.shape[0] - 1].reshape((1, x_sn.shape[1]))    \n",
    "        tmp1 = self._svm_kernel_function(X, x_sn)\n",
    "        #print(\"lam=\",self.lam.shape)\n",
    "        #print(\"y_sn=\",y_sn.shape)\n",
    "        #print(\"tmp1=\",tmp1.shape)        \n",
    "        tmp2 = self.lam.T * y_sn * tmp1\n",
    "        result = np.sum(tmp2, axis=1)\n",
    "        result[result < 0] = -1\n",
    "        result[result >= 0] = 1\n",
    "        \n",
    "        return result.astype('int8').T\n",
    "    \n",
    "    def _svm_kernel_function(self, X1, X2):\n",
    "        \"\"\"\n",
    "        SVM kernel関数\n",
    "        dot(X1(転置), X2)を計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_features, n_samples)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, n_samples)\n",
    "        \"\"\"\n",
    "        ans = np.dot(X1.T, X2)\n",
    "        return ans   \n",
    "\n",
    "    def _gradient_descent(self, X, y):\n",
    "        \"\"\"\n",
    "        説明を記述\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "        y : 次の形のndarray, shape (n_samples, 1)\n",
    "          正解値\n",
    "\n",
    "        Returns\n",
    "        -------        \n",
    "        \"\"\"\n",
    "\n",
    "        tmp1 = y.T * y * self.lam * self._svm_kernel_function(X, X)\n",
    "        delta = 1 - (np.sum(tmp1, axis=0))\n",
    "        delta = delta.reshape(len(delta), 1)\n",
    "        result = self.lam + self.lr * delta.T\n",
    "        #計算の都合で<0の結果は0に置き換える\n",
    "        result[result < 0] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _standval_to_actval(self, x):\n",
    "        tmp = x \n",
    "        tmp[tmp == 1] = self.label1_val\n",
    "        tmp[tmp == -1] = self.label0_val\n",
    "\n",
    "        return tmp\n",
    "    \n",
    "    def _actval_to_standval(self, x):\n",
    "        tmp = x\n",
    "        tmp[tmp == self.label0_val] = -1\n",
    "        tmp[tmp == self.label1_val] = 1\n",
    "        \n",
    "        return tmp\n",
    "        \n",
    "    def plot_boundary(self, x):\n",
    "        return\n",
    "    \n",
    "    def view_result(self):\n",
    "        print(self.sp_vector)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ScratchSVMClassifier(1000, 1e-8, False, C=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature, test_feature, train_target, test_target = train_test_split(data[['sepal length (cm)', 'petal length (cm)']].values, data['Species'].values, test_size=0.4, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#学習データの特徴量を標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_feature)\n",
    "train_feature = scaler.transform(train_feature)\n",
    "\n",
    "scaler.fit(test_feature)\n",
    "test_feature = scaler.transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial lambda:\n",
      "[[3.e-07 1.e-07 8.e-07 7.e-07 7.e-07 2.e-07 9.e-07 3.e-07 7.e-07 3.e-07\n",
      "  2.e-07 7.e-07 8.e-07 5.e-07 9.e-07 5.e-07 5.e-07 8.e-07 9.e-07 2.e-07\n",
      "  9.e-07 7.e-07 9.e-07 1.e-07 2.e-07 8.e-07 3.e-07 2.e-07 8.e-07 9.e-07\n",
      "  3.e-07 3.e-07 1.e-07 4.e-07 9.e-07 4.e-07 8.e-07 2.e-07 5.e-07 2.e-07\n",
      "  1.e-07 3.e-07 9.e-07 1.e-07 4.e-07 8.e-07 4.e-07 4.e-07 8.e-07 6.e-07\n",
      "  3.e-07 8.e-07 5.e-07 5.e-07 2.e-07 3.e-07 3.e-07 9.e-07 8.e-07 8.e-07]]\n",
      "Loop count=910\n",
      "Support vector=\n",
      "[[-0.12844329  0.19266494 -1.25232213  0.35321906 -1.09176801  0.19266494\n",
      "   0.51377318 -0.12844329  0.35321906]\n",
      " [-0.20412415  0.94407417 -0.45927933 -0.71443451 -1.09716728  1.45438453\n",
      "  -0.33170174 -0.33170174  0.81649658]\n",
      " [ 1.         -1.          1.          1.          1.         -1.\n",
      "   1.          1.         -1.        ]]\n",
      "Labe count 1:[6] -1:[3]\n",
      "tp=29 tn=26 fp=0 fn=0\n",
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_feature, train_target, test_feature, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp=16 tn=18 fp=0 fn=0\n",
      "1.0\n",
      "[-1  1  1  1  1 -1 -1  1 -1 -1  1  1 -1  1 -1  1 -1  1 -1 -1 -1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1  1  1 -1  1 -1  1  1 -1 -1]\n",
      "[-1  1  1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1 -1\n",
      " -1  1 -1 -1  1  1  1  1 -1 -1  1 -1  1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(test_feature)\n",
    "print(clf.cal_accuracy(pred, test_target))\n",
    "\n",
    "print(pred)\n",
    "print(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
