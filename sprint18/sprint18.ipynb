{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題1】学習と推定\n",
    "READMEを参考に上記実装を動かしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch=3 Iteration=100で学習した "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題2】論文と実装の対応\n",
    "コードリーディングを行ってください。\n",
    "まず、Faster R-CNN[1]において重要だと考えた部分を列挙してください。そして、それに対応するコードを見つけてください。\n",
    "（例）\n",
    "RPNを実現しているコードはどこか\n",
    "RoIプーリングを実現しているコードはどこか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.Modelを作る  \n",
    "    #config fileから学習したRPNのパラメータを読み込みモデルを構築(Resnet)\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "    # define the RPN, built on the base layers\n",
    "    num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "    # RPNのパラメータを与えRPNを作成\n",
    "    rpn = nn.rpn(shared_layers, num_anchors)\n",
    "    model_rpn = Model(img_input, rpn[:2])\n",
    "    # Loss関数==> クラス分類：losses.rpn_loss_cls BoundingBox位置の回帰 :losses.rpn_loss_regr\n",
    "    model_rpn.compile(optimizer=Adam(lr=1e-4), loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
    "    \n",
    "    #モデル\n",
    "    def rpn(base_layers,num_anchors):\n",
    "        x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
    "        x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
    "        x_regr = Convolution2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
    "        return [x_class, x_regr, base_layers]\n",
    "    \n",
    "    \n",
    "2.学習  \n",
    "    #Modelインスタンスを作成\n",
    "    model_rpn, model_classifier, model_all = faster_rcnn.get_model(C, classes_count)\n",
    "    \n",
    "    #Batch分ループを回し学習\n",
    "    #X=input image, Y=[Y_RPN_Class, Y_RPN_POS(x,y,h,w), Image(arugment関数へ入力されたoriginalイメージ）\n",
    "    X, Y, img_data = next(data_gen_train)\n",
    "    #RPNの学習\n",
    "    loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "\n",
    "3.予測  \n",
    "    #Modelインスタンスを作成\n",
    "    model_rpn, model_classifier, model_classifier_only = get_models(C)\n",
    "    #領域の予測\n",
    "    [Y1, Y2, F] = model_rpn.predict(X)\n",
    "    R = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.Modelを作る\n",
    "    classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
    "    model_classifier = Model([img_input, roi_input], classifier)\n",
    "    model_classifier.compile(optimizer=Adam(lr=1e-4), loss=[losses.class_loss_cls, losses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "\n",
    "    #モデル 内部にRoiPoolingを持つ\n",
    "    def classifier(base_layers, input_rois, num_rois, nb_classes = 21, trainable=False):\n",
    "        pooling_regions = 14\n",
    "        input_shape = (num_rois,14,14,1024)\n",
    "        out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
    "        out = classifier_layers(out_roi_pool, input_shape=input_shape, trainable=True)\n",
    "        out = TimeDistributed(Flatten())(out)\n",
    "        out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
    "        # note: no regression target for bg class\n",
    "        out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
    "        return [out_class, out_regr]    \n",
    "    \n",
    "2.学習 \n",
    "    loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "\n",
    "3.予測\n",
    "#RPNで領域候補を抽出\n",
    "[Y1, Y2, F] = model_rpn.predict(X)\n",
    "R = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n",
    "\n",
    "for jk in range(R.shape[0]//C.num_rois + 1):\n",
    "    ROIs = np.expand_dims(R[C.num_rois*jk:C.num_rois*(jk+1), :], axis=0)\n",
    "    if ROIs.shape[1] == 0:\n",
    "        break\n",
    "\n",
    "    if jk == R.shape[0]//C.num_rois:\n",
    "        #pad R\n",
    "        curr_shape = ROIs.shape\n",
    "        target_shape = (curr_shape[0],C.num_rois,curr_shape[2])\n",
    "        ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
    "        ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
    "        ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
    "        ROIs = ROIs_padded\n",
    "#Classifierでクラス分類と位置を取得\n",
    "    [P_cls, P_regr] = model_classifier_only.predict([F, ROIs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifierの内部にRoIPoolingを持つ\n",
    "def classifier(base_layers, input_rois, num_rois, nb_classes = 21, trainable=False):\n",
    "\n",
    "    pooling_regions = 14\n",
    "    input_shape = (num_rois,14,14,1024)\n",
    "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
    "    out = classifier_layers(out_roi_pool, input_shape=input_shape, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### シンプソンズのデータセットをFaster R-CNN以外の手法で学習・推定を行います。YOLOv3[2]のKeras実装を使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題3】学習済みの重みによる推定\n",
    "学習済みの重みを使い推定を行う方法がREADME.mdのQuick Startに記載されています。\n",
    "まずはこの通りにして各自何かしらの画像や動画に対して検出を行ってください。\n",
    "出力結果を課題の一部として提出してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"result_q3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習していないデータを入力したため、正しく分類できていない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題4】学習のためのファイルを作成\n",
    "新しいデータ（シンプソンズデータセット）を学習します。README.mdのTrainingを読み、シンプソンズデータセットを学習するために必要なファイルを作成してください。\n",
    "アノテーションファイルの形式がSprint18で扱った実装のものとは異なっているので、変換する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>52</td>\n",
       "      <td>72</td>\n",
       "      <td>abraham_grampa_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>337</td>\n",
       "      <td>354</td>\n",
       "      <td>abraham_grampa_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
       "      <td>128</td>\n",
       "      <td>48</td>\n",
       "      <td>285</td>\n",
       "      <td>407</td>\n",
       "      <td>abraham_grampa_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
       "      <td>72</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>275</td>\n",
       "      <td>abraham_grampa_simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
       "      <td>123</td>\n",
       "      <td>61</td>\n",
       "      <td>294</td>\n",
       "      <td>416</td>\n",
       "      <td>abraham_grampa_simpson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  x_min  y_min  x_max  \\\n",
       "0  simpsons_dataset/abraham_grampa_simpson/pic_00...     57     72     52   \n",
       "1  simpsons_dataset/abraham_grampa_simpson/pic_00...     80     31    337   \n",
       "2  simpsons_dataset/abraham_grampa_simpson/pic_00...    128     48    285   \n",
       "3  simpsons_dataset/abraham_grampa_simpson/pic_00...     72    126    158   \n",
       "4  simpsons_dataset/abraham_grampa_simpson/pic_00...    123     61    294   \n",
       "\n",
       "   y_max                class_id  \n",
       "0     72  abraham_grampa_simpson  \n",
       "1    354  abraham_grampa_simpson  \n",
       "2    407  abraham_grampa_simpson  \n",
       "3    275  abraham_grampa_simpson  \n",
       "4    416  abraham_grampa_simpson  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv(\"annotation.txt\")\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_name = np.unique(file[\"class_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_mapping = {label:idx for idx, label in enumerate(np.unique(file[\"class_id\"]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abraham_grampa_simpson': 0, 'apu_nahasapeemapetilon': 1, 'bart_simpson': 2, 'charles_montgomery_burns': 3, 'chief_wiggum': 4, 'comic_book_guy': 5, 'edna_krabappel': 6, 'homer_simpson': 7, 'kent_brockman': 8, 'krusty_the_clown': 9, 'lisa_simpson': 10, 'marge_simpson': 11, 'milhouse_van_houten': 12, 'moe_szyslak': 13, 'ned_flanders': 14, 'nelson_muntz': 15, 'principal_skinner': 16, 'sideshow_bob': 17}\n"
     ]
    }
   ],
   "source": [
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " file[\"class_id\"] =  file[\"class_id\"].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = file.reset_index(drop=True)\n",
    "filename = file[\"Filename\"].astype(str)\n",
    "x_min = file[\"x_min\"].astype(str)\n",
    "y_min = file[\"y_min\"].astype(str)\n",
    "x_max = file[\"x_max\"].astype(str)\n",
    "y_max = file[\"y_max\"].astype(str)\n",
    "class_id = file[\"class_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7889"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = filename + str(\" \") + x_min + str(\",\") + y_min + str(\",\") + x_max + str(\",\") + y_max + str(\",\") + class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.to_csv(\"train.txt\", index=False, sep='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = pd.DataFrame(class_name)\n",
    "cls.to_csv(\"simpsons_class.txt\", index=False, header=False, sep='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題5】学習\n",
    "問題2で作成したファイルを使用して学習してください。実行環境で学習に時間がかかる場合は、学習が行えることを確認するのみで終えて構いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yolo3_exec_result.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 【問題6】（アドバンス課題）論文と実装の対応\n",
    "コードリーディングを行ってください。\n",
    "まず、YOLOv3[2]の論文において重要だと考えた部分を列挙してください。そして、それに対応するコードを見つけてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
