{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/naoki/Desktop/DIC/Sprint/Sprint2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【問題1】train_test_splitのスクラッチ\n",
    "まずはスクラッチの練習として、scikit-learnのtrain_test_splitを自作してみましょう。Jupyter Notebookでコーディングを進め、完成後はpyファイルとします。utilsディレクトリの中にsplit.pyを作ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/naoki/Desktop/DIC/Sprint/utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x input\n",
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]]\n",
      "y input\n",
      "[[10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]]\n",
      "x train\n",
      "[[0 1]\n",
      " [6 7]\n",
      " [2 3]]\n",
      "x test\n",
      "[[10 11]\n",
      " [ 4  5]\n",
      " [ 8  9]]\n",
      "y train\n",
      "[10 13 11]\n",
      "y test\n",
      "[15 12 14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from utils.split import train_test_split\n",
    "\n",
    "x = np.array([i for i in range(12)]).reshape(6,2)\n",
    "y = np.array([i for i in range(10, 16)])\n",
    "y = y.reshape(len(y), 1)\n",
    "\n",
    "print(\"x input\")\n",
    "print(x)\n",
    "print(\"y input\")\n",
    "print(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, 0.5)\n",
    "print(\"x train\")\n",
    "print(x_train)\n",
    "print(\"x test\")\n",
    "print(x_test)\n",
    "print(\"y train\")\n",
    "print(y_train)\n",
    "print(\"y test\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【問題2】 分類パイプラインの作成\n",
    "分類は3種類の手法を扱います。pyファイルで実行できる分類のパイプラインを作成してください。  \n",
    "ロジスティック回帰  \n",
    "SVM  \n",
    "決定木  \n",
    "\n",
    "データセットは3種類用意します。3つのデータセットが引数により切り替えられるようにしてください。\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "virgicolorとvirginica\n",
    "また、残り2つは可視化が可能な特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from utils.sprint2_pipeline import pipeline_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_data_set = load_iris()\n",
    "X = pd.DataFrame(iris_data_set.data, columns=iris_data_set.feature_names)    #Put explanatory variable into x as pandasdata frame\n",
    "Y = pd.DataFrame(iris_data_set.target, columns=['Species'])    #Put iris response variable into y as pandasdata frame\n",
    "df = pd.concat([X, Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_feature_name = X.columns.values\n",
    "df = df[df[\"Species\"] != 0]\n",
    "X = df[selected_feature_name]\n",
    "Y = df[\"Species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irisデータに対して予想を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data train & test\n",
      "元データ数：100　学習データ数：75　検証データ数：25\n",
      "Normalize feature data\n",
      "Run GridSearch with 75 samples\n",
      "Set best params  {'C': 10, 'tol': 0.001}\n",
      "Result Format = binary\n",
      "Result(Pridiction)=\n",
      "[2 2 2 1 1 1 2 2 1 1 2 1 2 2 2 1 2 2 1 1 2 2 1 1 2]\n",
      "Answer=\n",
      "[2 2 2 1 1 1 1 2 1 1 1 1 2 1 2 1 2 2 1 1 2 2 1 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=30, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "#pipelineパラメーター\n",
    "params_ext = {\n",
    "            \"split_test_size\" : 0.25,\n",
    "            \"split_random_state\" : 42,\n",
    "            \"normalization_on\": True,\n",
    "            \"roc_plot_off\": True,\n",
    "            \"cv_on\": False,\n",
    "            \"cv_split\": 5,\n",
    "            \"cv_random_state\" : None,\n",
    "            \"cv_shuffle\" : True,\n",
    "            \"grid_search_on\" : True,\n",
    "            \"grid_search_samples\" : \"All\",\n",
    "            \"result_format\" : \"predict_as_binary\"\n",
    "        }\n",
    "#Grid search\n",
    "param_grid = {\n",
    "            \"hyper_param\":{\n",
    "                'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'tol' : [1e-3, 1e-4, 1e-5]\n",
    "            },\n",
    "            \"grid_search_param\":{\n",
    "                    \"grid_search_cv\":2\n",
    "            }\n",
    "        }\n",
    "\n",
    "result, answer, fpr, tpr, auc = pipeline_classifier(\n",
    "                                    clf, X.values, Y.values, \"Species\", selected_feature_name, 2, \n",
    "                                    params=params_ext, \n",
    "                                    params_grid=param_grid)\n",
    "\n",
    "\n",
    "print(\"Result(Pridiction)=\")\n",
    "print(result)\n",
    "print(\"Answer=\")\n",
    "print(answer.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data train & test\n",
      "元データ数：100　学習データ数：75　検証データ数：25\n",
      "Normalize feature data\n",
      "Result Format = binary\n",
      "Result(Pridiction)=\n",
      "[2 2 2 1 1 1 2 2 1 1 2 1 2 2 2 1 2 2 1 1 2 2 1 1 2]\n",
      "Answer=\n",
      "[2 2 2 1 1 1 1 2 1 1 1 1 2 1 2 1 2 2 1 1 2 2 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "#pipelineパラメーター\n",
    "params_ext = {\n",
    "            \"split_test_size\" : 0.25,\n",
    "            \"split_random_state\" : 42,\n",
    "            \"normalization_on\": True,\n",
    "            \"roc_plot_off\": True,\n",
    "            \"cv_on\": False,\n",
    "            \"cv_split\": 5,\n",
    "            \"cv_random_state\" : None,\n",
    "            \"cv_shuffle\" : True,\n",
    "            \"grid_search_on\" : False,\n",
    "            \"grid_search_samples\" : (int)(len(df.index)*0.75),\n",
    "            \"result_format\" : \"predict_as_binary\"\n",
    "        }\n",
    "#Grid search\n",
    "param_grid = {\n",
    "            \"hyper_param\":{\n",
    "                'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'tol' : [1e-3, 1e-4, 1e-5]\n",
    "            },\n",
    "            \"grid_search_param\":{\n",
    "                    \"grid_search_cv\":2\n",
    "            }\n",
    "        }\n",
    "\n",
    "selected_feature_name = X.columns.values\n",
    "\n",
    "result, answer, fpr, tpr, auc = pipeline_classifier(\n",
    "                                    clf, X.values, Y.values, \"Species\", selected_feature_name, 2, \n",
    "                                    params=params_ext, \n",
    "                                    params_grid=param_grid)\n",
    "\n",
    "print(\"Result(Pridiction)=\")\n",
    "print(result)\n",
    "print(\"Answer=\")\n",
    "print(answer.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data train & test\n",
      "元データ数：100　学習データ数：75　検証データ数：25\n",
      "Normalize feature data\n",
      "Result Format = binary\n",
      "Result(Pridiction)=\n",
      "[1 2 2 1 1 1 1 2 1 1 1 1 2 2 2 1 2 2 1 1 2 2 2 1 1]\n",
      "Answer=\n",
      "[2 2 2 1 1 1 1 2 1 1 1 1 2 1 2 1 2 2 1 1 2 2 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "#pipelineパラメーター\n",
    "params_ext = {\n",
    "            \"split_test_size\" : 0.25,\n",
    "            \"split_random_state\" : 42,\n",
    "            \"normalization_on\": True,\n",
    "            \"roc_plot_off\": True,\n",
    "            \"cv_on\": False,\n",
    "            \"cv_split\": 5,\n",
    "            \"cv_random_state\" : None,\n",
    "            \"cv_shuffle\" : True,\n",
    "            \"grid_search_on\" : False,\n",
    "            \"grid_search_samples\" : (int)(len(df.index)*0.75),\n",
    "            \"result_format\" : \"predict_as_binary\"\n",
    "        }\n",
    "#Grid search\n",
    "param_grid = {\n",
    "            \"hyper_param\":{\n",
    "                'max_depth' : [3, 10, 20],\n",
    "            },\n",
    "            \"grid_search_param\":{\n",
    "                    \"grid_search_cv\":2\n",
    "            }\n",
    "        }\n",
    "\n",
    "selected_feature_name = X.columns.values\n",
    "\n",
    "result, answer, fpr, tpr, auc = pipeline_classifier(\n",
    "                                    clf, X.values, Y.values, \"Species\", selected_feature_name, 2, \n",
    "                                    params=params_ext, \n",
    "                                    params_grid=param_grid)\n",
    "\n",
    "print(\"Result(Pridiction)=\")\n",
    "print(result)\n",
    "print(\"Answer=\")\n",
    "print(answer.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### シンプルデータセット1作成コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0= [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "Y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data train & test\n",
      "元データ数：500　学習データ数：375　検証データ数：125\n",
      "Normalize feature data\n",
      "Result Format = binary\n",
      "Result(Pridiction)=\n",
      "[-1  1  1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1 -1\n",
      " -1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1  1 -1 -1  1  1 -1  1  1\n",
      " -1 -1 -1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1\n",
      " -1  1  1  1 -1 -1  1 -1  1  1  1 -1  1  1  1 -1  1 -1 -1  1 -1 -1  1 -1\n",
      " -1 -1  1  1 -1]\n",
      "Answer=\n",
      "[-1  1  1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1 -1\n",
      " -1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1\n",
      "  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1  1 -1 -1  1  1 -1  1  1\n",
      " -1 -1 -1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1 -1 -1 -1 -1  1\n",
      " -1  1  1  1 -1 -1  1 -1  1  1  1 -1  1  1  1 -1  1 -1 -1  1 -1 -1  1 -1\n",
      " -1 -1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "#pipelineパラメーター\n",
    "params_ext = {\n",
    "            \"split_test_size\" : 0.25,\n",
    "            \"split_random_state\" : 42,\n",
    "            \"normalization_on\": True,\n",
    "            \"roc_plot_off\": True,\n",
    "            \"cv_on\": False,\n",
    "            \"cv_split\": 5,\n",
    "            \"cv_random_state\" : None,\n",
    "            \"cv_shuffle\" : True,\n",
    "            \"grid_search_on\" : False,\n",
    "            \"grid_search_samples\" : (int)(len(X)*0.75),\n",
    "            \"result_format\" : \"predict_as_binary\"\n",
    "        }\n",
    "#Grid search\n",
    "param_grid = {\n",
    "            \"hyper_param\":{\n",
    "                'max_depth' : [3, 10, 20],\n",
    "            },\n",
    "            \"grid_search_param\":{\n",
    "                    \"grid_search_cv\":2\n",
    "            }\n",
    "        }\n",
    "\n",
    "selected_feature_name = [\"A\", \"B\"]\n",
    "result, answer, fpr, tpr, auc = pipeline_classifier(\n",
    "                                    clf, X, Y, \"TARGET\", selected_feature_name, 2, \n",
    "                                    params=params_ext, \n",
    "                                    params_grid=param_grid)\n",
    "\n",
    "print(\"Result(Pridiction)=\")\n",
    "print(result)\n",
    "print(\"Answer=\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### シンプルデータセット2作成コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "Y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 2)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "#X = X.reshape(X.shape[0], X.shape[1])\n",
    "#y = y.reshape(y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data train & test\n",
      "元データ数：40　学習データ数：30　検証データ数：10\n",
      "Normalize feature data\n",
      "Run GridSearch with 30 samples\n",
      "Set best params  {'max_depth': 3}\n",
      "Result Format = binary\n",
      "Result(Pridiction)=\n",
      "[0 0 1 0 1 1 1 1 1 0]\n",
      "Answer=\n",
      "[0 0 0 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "#pipelineパラメーター\n",
    "params_ext = {\n",
    "            \"split_test_size\" : 0.25,\n",
    "            \"split_random_state\" : 42,\n",
    "            \"normalization_on\": True,\n",
    "            \"roc_plot_off\": True,\n",
    "            \"cv_on\": False,\n",
    "            \"cv_split\": 5,\n",
    "            \"cv_random_state\" : None,\n",
    "            \"cv_shuffle\" : True,\n",
    "            \"grid_search_on\" : True,\n",
    "            \"grid_search_samples\" : (int)(len(X)*0.75),\n",
    "            \"result_format\" : \"predict_as_binary\"\n",
    "        }\n",
    "#Grid search\n",
    "param_grid = {\n",
    "            \"hyper_param\":{\n",
    "                'max_depth' : [3, 10, 20],\n",
    "            },\n",
    "            \"grid_search_param\":{\n",
    "                    \"grid_search_cv\":2\n",
    "            }\n",
    "        }\n",
    "\n",
    "selected_feature_name = [\"A\", \"B\"]\n",
    "result, answer, fpr, tpr, auc = pipeline_classifier(\n",
    "                                    clf, X, Y, \"TARGET\", selected_feature_name, 2, \n",
    "                                    params=params_ext, \n",
    "                                    params_grid=param_grid)\n",
    "\n",
    "print(\"Result(Pridiction)=\")\n",
    "print(result)\n",
    "print(\"Answer=\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【問題3】 回帰パイプラインの作成\n",
    "回帰は1種類を扱います。pyファイルで実行できる回帰のパイプラインを作成してください。\n",
    "線形回帰\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "House Prices: Advanced Regression Techniques\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
